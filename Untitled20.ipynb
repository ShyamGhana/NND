{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQYYXJSQ9g7ca1RG/cDdSC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShyamGhana/NND/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. implementation of simple free forward neural network using numpy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "inputs = np.array([1, 2, 3])\n",
        "\n",
        "weights1 = np.array([\n",
        "    [4, 5],\n",
        "    [6, 7],\n",
        "    [8, 9]\n",
        "])\n",
        "\n",
        "bias1 = np.array([1, 2])\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "output = np.dot(inputs, weights1) + bias1\n",
        "print(\"Output:\", output)\n",
        "\n",
        "activated_output = sigmoid(output)\n",
        "print(\"Activated output:\", activated_output)\n",
        "\n",
        "activated_output2 = sigmoid(activated_output)\n",
        "print(\"Activated output:\", activated_output2)\n",
        "\n",
        "weights2 = np.array([\n",
        "    [0.1],\n",
        "    [0.2]\n",
        "])\n",
        "\n",
        "bias2 = np.array([1])\n",
        "\n",
        "final_output = np.dot(activated_output2, weights2) + bias2\n",
        "final_output = sigmoid(final_output)\n",
        "print(\"Final output:\", final_output)\n",
        "\n",
        "y = 1\n",
        "loss = (y - final_output) ** 2\n",
        "print(\"Loss:\", loss)\n",
        "\n",
        "lr = 0.1\n",
        "\n",
        "dloss_da2 = -2 * (y - final_output)\n",
        "da2_dz2 = final_output * (1 - final_output)\n",
        "dz2_dw2 = activated_output2.reshape(2, 1)\n",
        "\n",
        "grad_w2 = dloss_da2 * da2_dz2 * dz2_dw2\n",
        "weights2 = weights2 - lr * grad_w2\n",
        "\n",
        "print(\"Updated weights2:\", weights2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwEDJpso1GVh",
        "outputId": "39a634c2-da87-43d3-a4b6-52e6c8a0774f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: [41 48]\n",
            "Activated output: [1. 1.]\n",
            "Activated output: [0.73105858 0.73105858]\n",
            "Final output: [0.77194343]\n",
            "Loss: [0.0520098]\n",
            "Updated weights2: [[0.1058702]\n",
            " [0.2058702]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implement free forward NN using numpy with class\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class FeedForwardNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        self.weights1 = np.array([[4, 5],\n",
        "                                  [6, 7],\n",
        "                                  [8, 9]], dtype=float)\n",
        "\n",
        "        self.bias1 = np.array([1, 2], dtype=float)\n",
        "\n",
        "        self.weights2 = np.array([[0.1],\n",
        "                                  [0.2]], dtype=float)\n",
        "\n",
        "        self.bias2 = np.array([1], dtype=float)\n",
        "\n",
        "        self.lr = 0.1\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.z1 = np.dot(x, self.weights1) + self.bias1\n",
        "        self.a1 = self.sigmoid(self.z1)\n",
        "\n",
        "        self.z2 = np.dot(self.a1, self.weights2) + self.bias2\n",
        "        self.a2 = self.sigmoid(self.z2)\n",
        "\n",
        "        return self.a2\n",
        "\n",
        "    def compute_loss(self, y, y_pred):\n",
        "        return (y - y_pred) ** 2\n",
        "\n",
        "    def backward(self, x, y):\n",
        "        dloss_da2 = -2 * (y - self.a2)\n",
        "        da2_dz2 = self.sigmoid_derivative(self.a2)\n",
        "\n",
        "        grad_w2 = dloss_da2 * da2_dz2 * self.a1.reshape(2, 1)\n",
        "        grad_b2 = float(dloss_da2 * da2_dz2)\n",
        "\n",
        "        dloss_da1 = dloss_da2 * da2_dz2 * self.weights2.T\n",
        "        da1_dz1 = self.sigmoid_derivative(self.a1)\n",
        "\n",
        "        grad_w1 = x.reshape(3, 1) @ (dloss_da1 * da1_dz1)\n",
        "        grad_b1 = (dloss_da1 * da1_dz1).reshape(2,)\n",
        "\n",
        "        self.weights2 -= self.lr * grad_w2\n",
        "        self.bias2 -= self.lr * grad_b2\n",
        "\n",
        "        self.weights1 -= self.lr * grad_w1\n",
        "        self.bias1 -= self.lr * grad_b1\n",
        "\n",
        "    def train(self, x, y, epochs=1000):\n",
        "        for i in range(epochs):\n",
        "            y_pred = self.forward(x)\n",
        "            loss = self.compute_loss(y, y_pred)\n",
        "            self.backward(x, y)\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(\"Epoch:\", i + 1, \"Loss:\", loss)\n",
        "\n",
        "        return y_pred, loss\n",
        "\n",
        "\n",
        "x = np.array([1, 2, 3], dtype=float)\n",
        "y = 1\n",
        "\n",
        "model = FeedForwardNeuralNetwork()\n",
        "\n",
        "output = np.dot(x, model.weights1) + model.bias1\n",
        "print(\"Output:\", output)\n",
        "\n",
        "activated_output = model.sigmoid(output)\n",
        "print(\"Activated output:\", activated_output)\n",
        "\n",
        "activated_output2 = model.sigmoid(activated_output)\n",
        "print(\"Activated output:\", activated_output2)\n",
        "\n",
        "final_output, final_loss = model.train(x, y, epochs=1000)\n",
        "\n",
        "print(\"Final output:\", final_output)\n",
        "print(\"Loss:\", final_loss)\n",
        "print(\"Updated weights2:\", model.weights2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iFWpWay6r2W",
        "outputId": "bc9cabeb-4f69-4b28-ad6a-fc51df1340ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: [41. 48.]\n",
            "Activated output: [1. 1.]\n",
            "Activated output: [0.73105858 0.73105858]\n",
            "Epoch: 100 Loss: [0.00894483]\n",
            "Epoch: 200 Loss: [0.00467733]\n",
            "Epoch: 300 Loss: [0.00312809]\n",
            "Epoch: 400 Loss: [0.00233803]\n",
            "Epoch: 500 Loss: [0.00186173]\n",
            "Epoch: 600 Loss: [0.00154424]\n",
            "Epoch: 700 Loss: [0.00131793]\n",
            "Epoch: 800 Loss: [0.00114866]\n",
            "Epoch: 900 Loss: [0.00101741]\n",
            "Epoch: 1000 Loss: [0.00091273]\n",
            "Final output: [0.96978857]\n",
            "Loss: [0.00091273]\n",
            "Updated weights2: [[0.82312961]\n",
            " [0.92312961]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3035105013.py:43: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  grad_b2 = float(dloss_da2 * da2_dz2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implement free forward NN using tensorflow and keras\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = np.array([[1,2,3]], dtype=float)\n",
        "y = np.array([[1]], dtype=float)\n",
        "\n",
        "model = Sequential([Dense(2, activation=\"sigmoid\", input_shape=(3,)),\n",
        "                    Dense(1, activation=\"sigmoid\")])\n",
        "\n",
        "model.compile(optimizer=\"sgd\", loss=\"mse\")\n",
        "model.fit(x, y, epochs=100, verbose=0)\n",
        "print(\"Prediction:\", model.predict(x))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmw_jtyv9W-H",
        "outputId": "3de84ea0-38fe-43b8-eb60-3bc4ecc88f8c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Prediction: [[0.6017688]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Os7tST7FBw2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MMjnZvBuBxQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement free forward NN using Pytorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "x = torch.tensor([[1., 2., 3.]])\n",
        "y = torch.tensor([[1.]])\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(3, 2),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(2, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for _ in range(100):\n",
        "    y_pred = model(x)\n",
        "    loss = criterion(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Prediction:\", model(x).detach().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqO9ltP-AzdG",
        "outputId": "4e26ce96-2100-40ea-e070-7813898b32d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [[0.8748543]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJlMrh-yBwS9"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}